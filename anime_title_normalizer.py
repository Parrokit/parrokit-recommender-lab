import pandas as pd

import json
from openai import OpenAI
from dotenv import load_dotenv
import os

# 1) ë°ì´í„° ë¡œë“œ
df = pd.read_csv("data/animelist-dataset/new-anime-dataset-2023-with-korean.csv")

# 2) Korean Name / Korean Synopsis ì»¬ëŸ¼ ì—†ìœ¼ë©´ ì¶”ê°€ (NaNìœ¼ë¡œ ì´ˆê¸°í™”)
for col in ["Korean Name", "Korean Synopsis"]:
    if col not in df.columns:
        df[col] = pd.NA

# 3) Scoreê°€ UNKNOWNì´ ì•„ë‹Œ í–‰ë§Œ, ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
df_known = df[df['Score'] != "UNKNOWN"].copy()
df_sorted_score = df_known.sort_values('Score', ascending=False)

# 4) ì›ë³¸ dfì—ì„œ ì‚¬ìš©í•  ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì •ë ¬ëœ ìˆœì„œëŒ€ë¡œ)
sorted_indices = list(df_sorted_score.index)

len(sorted_indices), df.shape


load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = "gpt-4.1-mini"           # í•„ìš”í•˜ë©´ ë‹¤ë¥¸ ëª¨ë¸ëª…ìœ¼ë¡œ ë³€ê²½
client = OpenAI(api_key=OPENAI_API_KEY)

def call_translation_api(
    main_name: str,
    other_name: str,
    english_name: str,
    synopsis: str,
) -> dict:
    main_name = main_name or ""
    other_name = other_name or ""
    english_name = english_name or ""
    synopsis = synopsis or ""

    system_prompt = (
        "ë‹¹ì‹ ì€ ì¼ë³¸ ì• ë‹ˆë©”ì´ì…˜ ì •ë³´ë¥¼ í•œêµ­ì–´ë¡œ í˜„ì§€í™”í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. "
        "ì…ë ¥ìœ¼ë¡œ ì• ë‹ˆì˜ Main Name, Other Name, English Nameê³¼ ì˜ì–´ Synopsisê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤. "
        "í•œêµ­ì—ì„œ í†µìš©ë˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì• ë‹ˆ ì œëª©(Korean Name)ê³¼ "
        "í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­ëœ ì‹œë†‰ì‹œìŠ¤(Korean Synopsis)ë¥¼ ìƒì„±í•˜ì„¸ìš”. "
        "ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. í‚¤ ì´ë¦„ì€ 'korean_name', 'korean_synopsis' ì…ë‹ˆë‹¤."
    )

    user_prompt = f"""
ë‹¤ìŒ ì• ë‹ˆë©”ì´ì…˜ ì •ë³´ë¥¼ í•œêµ­ì–´ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

[Main Name]
{main_name}

[Other Name]
{other_name}

[English Name]
{english_name}

[Synopsis (EN)]
{synopsis}

ì¶œë ¥ í˜•ì‹ (JSON ì˜ˆì‹œ):

{{
  "korean_name": "ê°•ì² ì˜ ì—°ê¸ˆìˆ ì‚¬",
  "korean_synopsis": "ì—˜ë¦­ í˜•ì œê°€ ì—°ê¸ˆìˆ ì„ ì‚¬ìš©í•´..."
}}
"""

    try:
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.2,
            timeout=20.0,
        )
        content = resp.choices[0].message.content.strip()

        # ```json ... ``` í˜•íƒœë¡œ ì˜¤ëŠ” ê²½ìš° ì²˜ë¦¬
        if content.startswith("```"):
            content = content.strip("`")
            lines = content.splitlines()
            if lines and lines[0].strip().lower().startswith("json"):
                content = "\n".join(lines[1:])

        try:
            data = json.loads(content, strict=False)
        except json.JSONDecodeError as e:
            print("[API ERROR] JSON decode error:", e)
            print("[API ERROR] Raw content snippet:", content[:200])
            return {
                "korean_name": "",
                "korean_synopsis": "",
            }

        korean_name = data.get("korean_name", "").strip()
        korean_synopsis = data.get("korean_synopsis", "").strip()

        return {
            "korean_name": korean_name,
            "korean_synopsis": korean_synopsis,
        }

    except Exception as e:
        print("[API ERROR]", e)
        return {
            "korean_name": "",
            "korean_synopsis": "",
        }
    

from tqdm import tqdm
import pandas as pd
import json

def is_incomplete_like_annotator(kname, ksyn) -> bool:
    """KoreanAnnotator.find_next_incomplete_index()ì™€ ë™ì¼í•œ ê¸°ì¤€."""
    kname_empty = (isinstance(kname, str) and kname.strip() == "")
    ksyn_empty = (isinstance(ksyn, str) and ksyn.strip() == "")
    
    if pd.isna(kname) or pd.isna(ksyn) or kname_empty or ksyn_empty:
        return True
    return False

def auto_fill_korean_from_annotator_logic(
    df: pd.DataFrame,
    sorted_indices,
    save_path: str = "data/animelist-dataset/new-anime-dataset-2023-with-korean.csv",
    save_every: int = 20,
    show_synopsis: bool = False,
):
    total = len(sorted_indices)
    updated_count = 0

    print("=== ìë™ ë²ˆì—­ (KoreanAnnotator ë¡œì§ ê·¸ëŒ€ë¡œ) ì‹œì‘ ===")
    print(f"ì´ ëŒ€ìƒ í–‰: {total}\n")

    for i, idx in enumerate(tqdm(sorted_indices, desc="Translating anime", unit="anime")):
        row = df.loc[idx]

        # ê¸°ì¡´ ê°’
        kname_old = row.get("Korean Name")
        ksyn_old  = row.get("Korean Synopsis")

        # âœ… KoreanAnnotatorì™€ ë™ì¼í•œ 'ë¯¸ì™„ë£Œ' íŒì •
        if not is_incomplete_like_annotator(kname_old, ksyn_old):
            # ë‘˜ ë‹¤ ì±„ì›Œì ¸ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘ 
            continue

        # ì›ë³¸ ì •ë³´
        main_name = row.get("Name") or ""
        other_name = row.get("Other name") or ""
        english_name = (
            row.get("English name")
            if "English name" in df.columns
            else row.get("English Name")
        ) or ""
        syn = row.get("Synopsis") or ""

        # ğŸ” ë²ˆì—­ API í˜¸ì¶œ (suggestion ìƒì„±)
        auto = call_translation_api(
            str(main_name or ""),
            str(other_name or ""),
            str(english_name or ""),
            str(syn or ""),
        )
        suggested_kname = auto.get("korean_name", "") or ""
        suggested_ksyn  = auto.get("korean_synopsis", "") or ""

        # âœ… KoreanAnnotatorì™€ ë™ì¼í•œ ìš°ì„ ìˆœìœ„:
        #    - ê¸°ì¡´ ê°’ì´ ë¬¸ìì—´ì´ê³  ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ê·¸ê±¸ ìœ ì§€
        #    - ì•„ë‹ˆë©´ suggestion ì‚¬ìš©
        final_kname = (
            kname_old
            if isinstance(kname_old, str) and kname_old.strip() != ""
            else suggested_kname
        )
        final_ksyn = (
            ksyn_old
            if isinstance(ksyn_old, str) and ksyn_old.strip() != ""
            else suggested_ksyn
        )

        # ğŸ” ë¡œê·¸ë¡œ ë‹¤ ë³´ì—¬ì£¼ê¸°
        print("\n=======================================")
        print(f"[{updated_count+1}] index={idx} | Score={row.get('Score')}")
        print("=== ì›ë³¸ ì •ë³´ ===")
        print(f"- Main Name     : {main_name}")
        print(f"- Other Name    : {other_name}")
        print(f"- English Name  : {english_name}")
        if show_synopsis:
            print(f"- Synopsis (EN) : {syn[:250]}{'...' if len(syn) > 250 else ''}")

        print("\n=== ê¸°ì¡´ Korean ê°’ ===")
        print(f"- ê¸°ì¡´ Korean Name : {kname_old}")
        print(f"- ê¸°ì¡´ Korean Syn  : {ksyn_old[:150] if isinstance(ksyn_old, str) else ksyn_old}")

        print("\n=== ì œì•ˆ ë²ˆì—­(Suggestion) ===")
        print(f"- ì œì•ˆ Korean Name : {suggested_kname}")
        print(f"- ì œì•ˆ Korean Syn  : {suggested_ksyn[:150]}{'...' if len(suggested_ksyn) > 150 else ''}")

        print("\n=== ìµœì¢… ì ìš© ê°’(Final) ===")
        print(f"â¡ï¸ ìµœì¢… Korean Name : {final_kname}")
        print(f"â¡ï¸ ìµœì¢… Korean Syn  : {final_ksyn[:150] if isinstance(final_ksyn, str) else final_ksyn}")
        print("=======================================")

        # dfì— ìµœì¢… ê°’ ì €ì¥
        df.at[idx, "Korean Name"] = final_kname
        df.at[idx, "Korean Synopsis"] = final_ksyn
        updated_count += 1

        # ì¤‘ê°„ ì €ì¥
        if updated_count % save_every == 0:
            df.to_csv(save_path, index=False)
            print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ -> {save_path}")

    df.to_csv(save_path, index=False)
    print("\n=== ìë™ ë²ˆì—­ ì™„ë£Œ ===")
    print(f"ì´ ì—…ë°ì´íŠ¸ëœ í–‰: {updated_count}")
    print(f"íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {save_path}")

    return df

save_path = "data/animelist-dataset/new-anime-dataset-2023-with-korean.csv"

df = auto_fill_korean_from_annotator_logic(
    df=df,
    sorted_indices=sorted_indices,
    save_path=save_path,
    save_every=10,
    show_synopsis=False,  # Trueë¡œ í•˜ë©´ EN ì‹œë†‰ë„ ê°™ì´ ì°í˜
)